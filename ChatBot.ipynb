{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b711efa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Emirhan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69af893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pickle\n",
    "import random\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4740b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tag': 'greeting', 'patterns': ['Merhaba', 'Nasılsın', 'Selam', 'Sa', 'İyi günler'], 'responses': ['Merhaba, teşekkürler', 'Seni yeniden görmek güzel', 'Selam, nasıl yardımcı olabilirim?'], 'context': ['']}\n"
     ]
    }
   ],
   "source": [
    "#read json file\n",
    "with open('bot.json' , encoding='utf-8') as f:\n",
    "    data=json.load(f)\n",
    "    print(data['intents'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf6e931c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Merhaba'], 'greeting'), (['Nasılsın'], 'greeting'), (['Selam'], 'greeting'), (['Sa'], 'greeting'), (['İyi', 'günler'], 'greeting'), (['Görüşürüz'], 'goodbye'), (['Sonra', 'görüşürüz'], 'goodbye'), (['Seninle', 'konuşmak', 'güzeldi', ',', 'görüşürüz'], 'goodbye'), (['bye'], 'goodbye'), (['Teşekkürler'], 'thanks'), (['Teşekkür', 'ederim'], 'thanks'), (['Çok', 'yardımcı', 'oldun'], 'thanks'), (['Güzel', ',', 'teşekkürler'], 'thanks'), (['Yardım', 'ettiğin', 'için', 'teşekkürler'], 'thanks'), (['Bana', 'nasıl', 'yardımcı', 'olabilirsin', '?'], 'options'), (['Benim', 'için', 'ne', 'yapabilirsin'], 'options'), (['Bana', 'nasıl', 'yardım', 'edebilirsin', '?'], 'options'), (['Bana', 'yardım', 'etmelisin', '?'], 'options'), (['Yardımına', 'ihtiyacım', 'var'], 'options'), (['satın', 'aldığım', 'ürünü', 'nasıl', 'iade', 'edebilirim'], 'ürün_iadesi'), (['iade', 'işlemleri', 'için', 'neler', 'yapmam', 'gerekiyor', '?'], 'ürün_iadesi'), (['ürün', 'iade', 'edecektim'], 'ürün_iadesi'), (['ürün', 'iade', 'süresi', 'ne', 'kadar', '?'], 'ürün_iadesi'), (['iade', 'için', 'hangi', 'kargo', 'şirketini', 'kullanmam', 'gerekiyor'], 'ürün_iadesi'), (['Müşteri', 'hizmetleri', 'ile', 'görüşmek', 'istiyorum'], 'müşteri_hizmetleri'), (['Biri', 'ile', 'görüşmek', 'istiyorum'], 'müşteri_hizmetleri'), (['Konuşabileceğim', 'birini', 'istiyorum'], 'müşteri_hizmetleri'), (['Müşteri', 'hizmetlerine', 'bağlanmak', 'istiyorum'], 'müşteri_hizmetleri'), (['ürün', 'hakkında', 'bilgi', 'almak', 'istiyorum'], 'ürün_tanıtımı'), (['Ürünün', 'özellikleri', 'neler', '?'], 'ürün_tanıtımı'), (['ürünün', 'fiyatı', 'ne', 'kadar', '?'], 'ürün_tanıtımı'), (['ürün', 'hakkında', 'neler', 'söyleyebilirsiniz'], 'ürün_tanıtımı'), (['ürünü', 'neden', 'satın', 'almalıyım', '?'], 'ürün_tanıtımı'), (['kargom', 'nerede', '?'], 'kargo_takip'), (['kargomun', 'konumu'], 'kargo_takip'), (['kargom', 'kaç', 'güne', 'gelir', '?'], 'kargo_takip'), (['kargom', 'ne', 'zaman', 'elime', 'ulaşır'], 'kargo_takip'), (['kargo', 'dağıtıma', 'çıktımı'], 'kargo_takip'), (['siparişimi', 'iptal', 'etmek', 'istiyorum'], 'ürün_iptali'), (['sipariş', 'iptali'], 'ürün_iptali'), (['ürün', 'iptali'], 'ürün_iptali'), (['satın', 'alımı', 'iptal', 'etmek', 'istiyorum'], 'ürün_iptali')]\n"
     ]
    }
   ],
   "source": [
    "#tokenization\n",
    "words=[]\n",
    "classes=[]\n",
    "documents=[]\n",
    "ignore_words=['?']\n",
    "#get into  json\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        #tokenize each word in the sentence\n",
    "        w=nltk.word_tokenize(pattern)\n",
    "        #add words into list\n",
    "        words.extend(w)#get words one by one\n",
    "        #add into documents our corpus\n",
    "        documents.append((w,intent['tag']))\n",
    "        #add our classes into list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "print(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a154e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "42\n",
      "9\n",
      "[',', 'aldığım', 'almak', 'almalıyım', 'alımı', 'ban', 'bağlanmak', 'benim', 'bilg', 'bir', 'birin', 'bye', 'dağıtım', 'edebilirim', 'edebilirsin', 'edecektim', 'ederim', 'elim', 'etmek', 'etmelisin', 'ettiğin', 'fiyatı', 'gelir', 'gerekiy', 'görüşmek', 'görüşürüz', 'güne', 'günler', 'güzel', 'güzeldi', 'hakkınd', 'hang', 'hizmetler', 'hizmetlerin', 'iad', 'ihtiyacım', 'il', 'ipt', 'iptal', 'istiyor', 'için', 'işlemler', 'i̇y', 'kad', 'kargo', 'kargom', 'kargomun', 'kaç', 'konumu', 'konuşabileceğim', 'konuşmak', 'kullanmam', 'merhab', 'müşteri', 'nasıl', 'nasılsın', 'ne', 'ned', 'nel', 'ner', 'olabilirsin', 'oldun', 'sa', 'satın', 'selam', 'seninl', 'sipariş', 'siparişim', 'sonr', 'söyleyebilirsin', 'süresi', 'teşekkür', 'teşekkürl', 'ulaşır', 'var', 'yapabilirsin', 'yapmam', 'yardım', 'yardımcı', 'yardımın', 'zam', 'çok', 'çıktımı', 'özellikler', 'ürün', 'ürünü', 'ürünün', 'şirketin']\n"
     ]
    }
   ],
   "source": [
    "#stem and lower each word, remove duplicates\n",
    "words=[stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "words=sorted(list(set(words)))\n",
    "print(len(words))\n",
    "print(len(documents))\n",
    "print(len(classes))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d791b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0]], [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0]], [[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1]], [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1]]]\n"
     ]
    }
   ],
   "source": [
    "#create training data\n",
    "training=[]\n",
    "output_empty=[0]*len(classes)\n",
    "for doc in documents:\n",
    "    bag=[]\n",
    "    pattern_words=doc[0]\n",
    "    pattern_words=[stemmer.stem(word.lower())for word in pattern_words]\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0) # create our bag of words array with 1, if word match found in current pattern\n",
    "     # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "    output_row=list(output_empty)\n",
    "    output_row[classes.index(doc[1])]=1\n",
    "    training.append([bag, output_row])\n",
    "print(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61f418cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\threepointseven\\lib\\site-packages\\ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#shuffle features and convert into np.array\n",
    "random.shuffle(training)\n",
    "training=np.array(training)\n",
    "#create train and test list \n",
    "train_x=list(training[:,0])\n",
    "print(len(train_x))\n",
    "train_y=list(training[:,1])\n",
    "print(len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea1f3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               22784     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 64,521\n",
      "Trainable params: 64,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#creation of model 4 layers\n",
    "model=Sequential()\n",
    "model.add(Dense(256, input_shape=(len(train_x[0]),),activation='relu'))#first layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))#secod layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))#third layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]),activation='softmax'))#4th and output layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcae08a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model with sgd optimizer\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True);\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "521b1a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2766 - accuracy: 0.0714\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1898 - accuracy: 0.0952\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2023 - accuracy: 0.0714\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1675 - accuracy: 0.1190\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1287 - accuracy: 0.1667\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0702 - accuracy: 0.1429\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0307 - accuracy: 0.2857\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.9446 - accuracy: 0.2857\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.9817 - accuracy: 0.2619\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.9172 - accuracy: 0.2857\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7809 - accuracy: 0.3571\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.8170 - accuracy: 0.4286\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6860 - accuracy: 0.4524\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.5399 - accuracy: 0.5476\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.3113 - accuracy: 0.4762\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.3857 - accuracy: 0.5714\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.1215 - accuracy: 0.6429\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.0738 - accuracy: 0.6667\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.1053 - accuracy: 0.6667\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9318 - accuracy: 0.7857\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9415 - accuracy: 0.6905\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.8014 - accuracy: 0.7619\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7170 - accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7349 - accuracy: 0.7619\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5929 - accuracy: 0.8095\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.8810\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.8810\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3030 - accuracy: 0.9524\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8810\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3144 - accuracy: 0.9048\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.9286\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2127 - accuracy: 0.9524\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9286\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.8810\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9524\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2645 - accuracy: 0.9048\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.9524\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9048\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1707 - accuracy: 0.9762\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.9524\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1702 - accuracy: 0.9762\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9762\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.9048\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9524\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.9048\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2799 - accuracy: 0.9286\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.9048\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9524\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.9762\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.9762\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2542 - accuracy: 0.9286\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.9286\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9762\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9524\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 998us/step - loss: 0.0926 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.2235 - accuracy: 0.9524\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.9762\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.1280 - accuracy: 0.9762\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.1320 - accuracy: 0.9762\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1383 - accuracy: 0.9762\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0651 - accuracy: 0.9762\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0897 - accuracy: 0.9762\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0499 - accuracy: 0.9762\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9762\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.9524\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0792 - accuracy: 0.9524\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9524\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9524\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0491 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 999us/step - loss: 0.0559 - accuracy: 0.9762\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9762\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9762\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.9524\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.9762\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1433 - accuracy: 0.9524\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.1064 - accuracy: 0.9762\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.0952 - accuracy: 0.9762\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9762\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0534 - accuracy: 0.9762\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9524\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 998us/step - loss: 0.1041 - accuracy: 0.9524\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 998us/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9762\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9762\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0553 - accuracy: 0.9762\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0440 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1459 - accuracy: 0.9524\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0476 - accuracy: 0.9762\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0821 - accuracy: 0.9762\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.1877 - accuracy: 0.9762\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9524\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9762\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0474 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9762\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9762\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9762\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.1499 - accuracy: 0.9524\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 996us/step - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9762\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9762\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 996us/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9762\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9524\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 999us/step - loss: 0.0262 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9524\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0552 - accuracy: 0.9762\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0352 - accuracy: 0.9762\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9524\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9762\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9762\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0274 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9524\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0806 - accuracy: 0.9762\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9762\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 9.4211e-04 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9762\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0281 - accuracy: 0.9762\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.9524\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0719 - accuracy: 0.9762\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0499 - accuracy: 0.9762\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9762\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1020 - accuracy: 0.9762\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9762\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0367 - accuracy: 0.9762\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9762\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0833 - accuracy: 0.9524\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9524\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0760 - accuracy: 0.9762\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x272b0d17308>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model\n",
    "model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4c0d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data from user will be tokenized\n",
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern - split words into array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word - create short form for word\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=True):\n",
    "    #run tokenization\n",
    "    sentence_words=clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6b74237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in bag: selam\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "p=bow('Selam', words)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94e6560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_path = C:\\Users\\Emirhan\\AppData\\Local\\Temp\\1\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\threepointseven\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\threepointseven\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Emirhan\\AppData\\Local\\Temp\\1\\assets\n",
      "\n",
      "Saved model:C:\\Users\\Emirhan\\AppData\\Local\\Temp\\1\\saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "#model saved\n",
    "import tempfile\n",
    "import os\n",
    "MODEL_DIR = tempfile.gettempdir()\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")\n",
    "\n",
    "print(f'\\nSaved model:{export_path}\\saved_model.pb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2737666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_local(sentence):\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    \n",
    "    # generate probabilities from the model\n",
    "    input_data = pd.DataFrame([bow(sentence, words)], dtype=float, index=['input'])\n",
    "    results = model.predict([input_data])[0]\n",
    "    print(\"similarity results:\",results)\n",
    "    # filter out predictions below a threshold, and provide intent index\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], str(r[1])))\n",
    "    # return tuple of intent and probability\n",
    "    return response(return_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bb35ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(return_list):#set response\n",
    "    answer=[]\n",
    "    for intent in data['intents']:\n",
    "        if return_list[0][0]==intent['tag']:\n",
    "            print(intent['tag'])\n",
    "            return random.choice(intent['responses'])#pick one of random answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f6d7c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in bag: ürün\n",
      "found in bag: hakkınd\n",
      "found in bag: bilg\n",
      "similarity results: [1.1986948e-09 1.9385192e-07 7.7731259e-11 6.2376410e-12 3.7881280e-09\n",
      " 1.7768538e-11 9.9999976e-01 2.7178799e-09 3.0338843e-08]\n",
      "ürün_tanıtımı\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hangi üründen bahsediyorsunuz kodunu alabilir miyim'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_local('ürün hakkında bilgi istiyordum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a081ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "user=input(\"Nasıl yardımcı olabilirim\")\n",
    "classify_local(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b430c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
